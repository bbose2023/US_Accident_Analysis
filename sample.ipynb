{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3eb9c7-e42c-4eb4-8f6c-6a9003402fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Import Dependencies\n",
    "import psycopg2\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "from utils import createCSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fac21b6-df8b-447d-9e5c-fa3d57e4bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import chardet as chardet\n",
    "import dask as dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b5e426-af8f-42fc-b985-2d5bbc34d93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e573c765-9291-491e-8920-fd289bf5b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCSV(original_csv_file_name, lst_label_name, new_csv_file_name):\n",
    "    orig_csv_file_path = Path(f\"Resources/{original_csv_file_name}.csv\")\n",
    "    # Define the file path\n",
    "    with open(orig_csv_file_path, 'rb') as f:\n",
    "        result = chardet.detect(f.read())\n",
    "        detected_encoding = result['encoding']\n",
    "   \n",
    "    lbl_names_file_path = Path(f\"Resources/{lst_label_name}.csv\")\n",
    "   \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df_original_csv = pd.read_csv(orig_csv_file_path, encoding=detected_encoding)\n",
    "    df_labels_csv = pd.read_csv(lbl_names_file_path)\n",
    "    df_new_csv_file = pd.DataFrame([])\n",
    "    # # loop through label_names and get each label\n",
    "    for col in df_labels_csv.columns:\n",
    "        df_new_csv_file[col] = df_original_csv[col]\n",
    "\n",
    "    print(df_new_csv_file.info())\n",
    "\n",
    "    #Save the new cleaned data file\n",
    "    cleaned_csv_path = Path(f\"Resources/{new_csv_file_name}.csv\")\n",
    "    df_new_csv_file.to_csv(cleaned_csv_path, index=False)\n",
    "\n",
    "def createCSVUsingDask(orig_csv_file_path, lbl_names_file_path, new_csv_file_name):\n",
    "    \n",
    "    print(\"Starting to read the File\")\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df_original_csv = dd.read_csv(orig_csv_file_path)\n",
    "    print(f\"################Original File################# {df_original_csv}\")\n",
    "    \n",
    "    df_labels_csv = pd.read_csv(lbl_names_file_path)\n",
    "    print(f\"################Labels to save###################### {df_labels_csv}\")\n",
    "    print(df_original_csv.columns)\n",
    "    # Create a list of columns to keep\n",
    "    columns_to_keep = df_labels_csv.columns\n",
    "    # [col for col in df_original_csv.columns if col not in df_labels_csv.columns]\n",
    "    print(columns_to_keep.tolist())\n",
    "    # Select only the desired columns\n",
    "    # dask.config.set({\"dataframe.convert-string\": False})\n",
    "    df = df_original_csv.drop(columns=columns_to_keep.tolist(),axis=1)\n",
    "    # df = df_original_csv[columns_to_keep]\n",
    "    print(df)\n",
    "    #########################Saving of the CSV file doesn't work#############################\n",
    "    # Save the transformed DataFrame to a new CSV scroll    \n",
    "    # cleaned_csv_path = Path(f\"Resources/{new_csv_file_name}.csv\")\n",
    "    # df.to_csv(cleaned_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982ae575-7196-4b9c-bd8c-8e5889a447eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to read the File\n",
      "################Original File################# Dask DataFrame Structure:\n",
      "               STATE STATENAME ST_CASE   PEDS PERNOTMVIT VE_TOTAL VE_FORMS PVH_INVL PERSONS PERMVIT COUNTY COUNTYNAME   CITY CITYNAME  MONTH MONTHNAME    DAY DAYNAME DAY_WEEK DAY_WEEKNAME   YEAR   HOUR HOURNAME MINUTE MINUTENAME TWAY_ID TWAY_ID2  ROUTE ROUTENAME RUR_URB RUR_URBNAME FUNC_SYS FUNC_SYSNAME RD_OWNER RD_OWNERNAME    NHS NHSNAME SP_JUR SP_JURNAME MILEPT MILEPTNAME LATITUDE LATITUDENAME LONGITUD LONGITUDNAME HARM_EV HARM_EVNAME MAN_COLL MAN_COLLNAME RELJCT1 RELJCT1NAME RELJCT2 RELJCT2NAME TYP_INT TYP_INTNAME REL_ROAD REL_ROADNAME WRK_ZONE WRK_ZONENAME LGT_COND LGT_CONDNAME WEATHER WEATHERNAME SCH_BUS SCH_BUSNAME   RAIL RAILNAME NOT_HOUR NOT_HOURNAME NOT_MIN NOT_MINNAME ARR_HOUR ARR_HOURNAME ARR_MIN ARR_MINNAME HOSP_HR HOSP_HRNAME HOSP_MN HOSP_MNNAME FATALS\n",
      "npartitions=1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "               int64    string   int64  int64      int64    int64    int64    int64   int64   int64  int64     string  int64   string  int64    string  int64   int64    int64       string  int64  int64   string  int64      int64  string   string  int64    string   int64      string    int64       string    int64       string  int64  string  int64     string  int64    float64  float64      float64  float64      float64   int64      string    int64       string   int64      string   int64      string   int64      string    int64       string    int64      float64    int64       string   int64      string   int64      string  int64   string    int64       string   int64      string    int64       string   int64      string   int64      string   int64      string  int64\n",
      "                 ...       ...     ...    ...        ...      ...      ...      ...     ...     ...    ...        ...    ...      ...    ...       ...    ...     ...      ...          ...    ...    ...      ...    ...        ...     ...      ...    ...       ...     ...         ...      ...          ...      ...          ...    ...     ...    ...        ...    ...        ...      ...          ...      ...          ...     ...         ...      ...          ...     ...         ...     ...         ...     ...         ...      ...          ...      ...          ...      ...          ...     ...         ...     ...         ...    ...      ...      ...          ...     ...         ...      ...          ...     ...         ...     ...         ...     ...         ...    ...\n",
      "Dask Name: read_csv, 1 expression\n",
      "Expr=ReadCSV(5db41e4)\n",
      "################Labels to save###################### Empty DataFrame\n",
      "Columns: [STATE, STATENAME, ST_CASE, PEDS, PERNOTMVIT, VE_TOTAL, VE_FORMS, PVH_INVL, PERSONS, PERMVIT, COUNTY, COUNTYNAME, CITY, CITYNAME, MONTH, MONTHNAME, DAY, DAYNAME, DAY_WEEK, DAY_WEEKNAME, YEAR, HOUR, HOURNAME, MINUTE, MINUTENAME, TWAY_ID, TWAY_ID2, ROUTE]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 28 columns]\n",
      "Index(['STATE', 'STATENAME', 'ST_CASE', 'PEDS', 'PERNOTMVIT', 'VE_TOTAL',\n",
      "       'VE_FORMS', 'PVH_INVL', 'PERSONS', 'PERMVIT', 'COUNTY', 'COUNTYNAME',\n",
      "       'CITY', 'CITYNAME', 'MONTH', 'MONTHNAME', 'DAY', 'DAYNAME', 'DAY_WEEK',\n",
      "       'DAY_WEEKNAME', 'YEAR', 'HOUR', 'HOURNAME', 'MINUTE', 'MINUTENAME',\n",
      "       'TWAY_ID', 'TWAY_ID2', 'ROUTE', 'ROUTENAME', 'RUR_URB', 'RUR_URBNAME',\n",
      "       'FUNC_SYS', 'FUNC_SYSNAME', 'RD_OWNER', 'RD_OWNERNAME', 'NHS',\n",
      "       'NHSNAME', 'SP_JUR', 'SP_JURNAME', 'MILEPT', 'MILEPTNAME', 'LATITUDE',\n",
      "       'LATITUDENAME', 'LONGITUD', 'LONGITUDNAME', 'HARM_EV', 'HARM_EVNAME',\n",
      "       'MAN_COLL', 'MAN_COLLNAME', 'RELJCT1', 'RELJCT1NAME', 'RELJCT2',\n",
      "       'RELJCT2NAME', 'TYP_INT', 'TYP_INTNAME', 'REL_ROAD', 'REL_ROADNAME',\n",
      "       'WRK_ZONE', 'WRK_ZONENAME', 'LGT_COND', 'LGT_CONDNAME', 'WEATHER',\n",
      "       'WEATHERNAME', 'SCH_BUS', 'SCH_BUSNAME', 'RAIL', 'RAILNAME', 'NOT_HOUR',\n",
      "       'NOT_HOURNAME', 'NOT_MIN', 'NOT_MINNAME', 'ARR_HOUR', 'ARR_HOURNAME',\n",
      "       'ARR_MIN', 'ARR_MINNAME', 'HOSP_HR', 'HOSP_HRNAME', 'HOSP_MN',\n",
      "       'HOSP_MNNAME', 'FATALS'],\n",
      "      dtype='object')\n",
      "['STATE', 'STATENAME', 'ST_CASE', 'PEDS', 'PERNOTMVIT', 'VE_TOTAL', 'VE_FORMS', 'PVH_INVL', 'PERSONS', 'PERMVIT', 'COUNTY', 'COUNTYNAME', 'CITY', 'CITYNAME', 'MONTH', 'MONTHNAME', 'DAY', 'DAYNAME', 'DAY_WEEK', 'DAY_WEEKNAME', 'YEAR', 'HOUR', 'HOURNAME', 'MINUTE', 'MINUTENAME', 'TWAY_ID', 'TWAY_ID2', 'ROUTE']\n",
      "Dask DataFrame Structure:\n",
      "              ROUTENAME RUR_URB RUR_URBNAME FUNC_SYS FUNC_SYSNAME RD_OWNER RD_OWNERNAME    NHS NHSNAME SP_JUR SP_JURNAME MILEPT MILEPTNAME LATITUDE LATITUDENAME LONGITUD LONGITUDNAME HARM_EV HARM_EVNAME MAN_COLL MAN_COLLNAME RELJCT1 RELJCT1NAME RELJCT2 RELJCT2NAME TYP_INT TYP_INTNAME REL_ROAD REL_ROADNAME WRK_ZONE WRK_ZONENAME LGT_COND LGT_CONDNAME WEATHER WEATHERNAME SCH_BUS SCH_BUSNAME   RAIL RAILNAME NOT_HOUR NOT_HOURNAME NOT_MIN NOT_MINNAME ARR_HOUR ARR_HOURNAME ARR_MIN ARR_MINNAME HOSP_HR HOSP_HRNAME HOSP_MN HOSP_MNNAME FATALS\n",
      "npartitions=1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "                 string   int64      string    int64       string    int64       string  int64  string  int64     string  int64    float64  float64      float64  float64      float64   int64      string    int64       string   int64      string   int64      string   int64      string    int64       string    int64      float64    int64       string   int64      string   int64      string  int64   string    int64       string   int64      string    int64       string   int64      string   int64      string   int64      string  int64\n",
      "                    ...     ...         ...      ...          ...      ...          ...    ...     ...    ...        ...    ...        ...      ...          ...      ...          ...     ...         ...      ...          ...     ...         ...     ...         ...     ...         ...      ...          ...      ...          ...      ...          ...     ...         ...     ...         ...    ...      ...      ...          ...     ...         ...      ...          ...     ...         ...     ...         ...     ...         ...    ...\n",
      "Dask Name: drop_by_shallow_copy, 2 expressions\n",
      "Expr=Drop(frame=ReadCSV(5db41e4), columns=['STATE', 'STATENAME', 'ST_CASE', 'PEDS', 'PERNOTMVIT', 'VE_TOTAL', 'VE_FORMS', 'PVH_INVL', 'PERSONS', 'PERMVIT', 'COUNTY', 'COUNTYNAME', 'CITY', 'CITYNAME', 'MONTH', 'MONTHNAME', 'DAY', 'DAYNAME', 'DAY_WEEK', 'DAY_WEEKNAME', 'YEAR', 'HOUR', 'HOURNAME', 'MINUTE', 'MINUTENAME', 'TWAY_ID', 'TWAY_ID2', 'ROUTE'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boseb\\anaconda3\\envs\\pythondata\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:555: UserWarning: Warning gzip compression does not support breaking apart files\n",
      "Please ensure that each individual file can fit in memory and\n",
      "use the keyword ``blocksize=None to remove this message``\n",
      "Setting ``blocksize=None``\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(\"Resources\")\n",
    "createCSVUsingDask(f\"{base_path}/accident_2022.csv.gz\",f\"{base_path}/accident_2022_label.csv\",\"us_accident_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72331138-3563-4cfd-b361-28e917369611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fddd26-6e9a-4868-9707-b528131134f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
