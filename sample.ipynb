{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3eb9c7-e42c-4eb4-8f6c-6a9003402fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Import Dependencies\n",
    "import psycopg2\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "from utils import createCSV,createCSVUsingDask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fac21b6-df8b-447d-9e5c-fa3d57e4bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import chardet as chardet\n",
    "import dask as dask\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e573c765-9291-491e-8920-fd289bf5b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createCSV(orig_csv_file_path, lbl_names_file_path, new_csv_file_name, mode):\n",
    "    \n",
    "#     # Code that helped to find the encoding error\n",
    "#     # with open(orig_csv_file_path, 'rb') as f:\n",
    "#     #     content = f.read()\n",
    "#     #     print(content[260920:260925]) \n",
    "#     print(\"Starting to read the File\")\n",
    "#     df_labels_csv = pd.read_csv(lbl_names_file_path)\n",
    "#     columns_to_keep = df_labels_csv.columns\n",
    "#     print(f\"################Labels to Save###################### {columns_to_keep}\")\n",
    "#     # Read the CSV file into a DataFrame\n",
    "#     df_original_csv = pd.read_csv(orig_csv_file_path, usecols=df_labels_csv.columns, encoding='latin-1')\n",
    "#     print(f\"################Updated CSV File################# {df_original_csv}\") \n",
    "#     #Save the new cleaned data file\n",
    "#     cleaned_csv_path = Path(f\"Resources/{new_csv_file_name}.csv\")\n",
    "#     df_original_csv.to_csv(cleaned_csv_path, index=False, mode=mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ce9619-7ff6-482f-8ffd-8ce3e01e09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createCSVUsingDask(orig_csv_file_path, lbl_names_file_path, new_csv_file_name, mode):\n",
    "    \n",
    "#     print(\"Starting to read the File\")\n",
    "\n",
    "#     df_labels_csv = pd.read_csv(lbl_names_file_path)\n",
    "#     # Create a list of columns to keep\n",
    "#     columns_to_keep = df_labels_csv.columns\n",
    "#     print(f\"################Labels to Save###################### {columns_to_keep}\")\n",
    "    \n",
    "#     # Read the CSV file into a DataFrame with the selected columns\n",
    "#     df_original_csv = dd.read_csv(orig_csv_file_path, usecols=columns_to_keep, encoding='latin-1',dtype={'MINUTENAME': 'object'})\n",
    "#     print(f\"################Updated CSV File################# {df_original_csv.columns}\")        \n",
    "   \n",
    "#     # Save the transformed DataFrame to a new CSV scroll    \n",
    "#     cleaned_csv_path = Path(f\"Resources/{new_csv_file_name}.csv\")\n",
    "#     df_original_csv.to_csv(cleaned_csv_path, index=False, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "982ae575-7196-4b9c-bd8c-8e5889a447eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to read the File\n",
      "################Labels to Save###################### Index(['STATE', 'STATENAME', 'ST_CASE', 'PEDS', 'PERNOTMVIT', 'VE_TOTAL',\n",
      "       'VE_FORMS', 'PVH_INVL', 'PERSONS', 'PERMVIT', 'COUNTY', 'COUNTYNAME',\n",
      "       'CITY', 'CITYNAME', 'MONTH', 'MONTHNAME', 'DAY', 'DAYNAME', 'DAY_WEEK',\n",
      "       'DAY_WEEKNAME', 'YEAR', 'HOUR', 'HOURNAME', 'MINUTE', 'MINUTENAME',\n",
      "       'TWAY_ID', 'TWAY_ID2', 'ROUTE'],\n",
      "      dtype='object')\n",
      "################Updated CSV File################# Index(['STATE', 'STATENAME', 'ST_CASE', 'PEDS', 'PERNOTMVIT', 'VE_TOTAL',\n",
      "       'VE_FORMS', 'PVH_INVL', 'PERSONS', 'PERMVIT', 'COUNTY', 'COUNTYNAME',\n",
      "       'CITY', 'CITYNAME', 'MONTH', 'MONTHNAME', 'DAY', 'DAYNAME', 'DAY_WEEK',\n",
      "       'DAY_WEEKNAME', 'YEAR', 'HOUR', 'HOURNAME', 'MINUTE', 'MINUTENAME',\n",
      "       'TWAY_ID', 'TWAY_ID2', 'ROUTE'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boseb\\anaconda3\\envs\\pythondata\\lib\\site-packages\\dask\\dataframe\\io\\csv.py:555: UserWarning: Warning gzip compression does not support breaking apart files\n",
      "Please ensure that each individual file can fit in memory and\n",
      "use the keyword ``blocksize=None to remove this message``\n",
      "Setting ``blocksize=None``\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(\"Resources\")\n",
    "createCSVUsingDask(f\"{base_path}/accident_2022.csv.gz\",f\"{base_path}/accident_2022_label.csv\",\"us_accident_2022_dask\",\"wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72331138-3563-4cfd-b361-28e917369611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to read the File\n",
      "################Labels to Save###################### Index(['STATE', 'STATENAME', 'ST_CASE', 'PEDS', 'PERNOTMVIT', 'VE_TOTAL',\n",
      "       'VE_FORMS', 'PVH_INVL', 'PERSONS', 'PERMVIT', 'COUNTY', 'COUNTYNAME',\n",
      "       'CITY', 'CITYNAME', 'MONTH', 'MONTHNAME', 'DAY', 'DAYNAME', 'DAY_WEEK',\n",
      "       'DAY_WEEKNAME', 'YEAR', 'HOUR', 'HOURNAME', 'MINUTE', 'MINUTENAME',\n",
      "       'TWAY_ID', 'TWAY_ID2', 'ROUTE'],\n",
      "      dtype='object')\n",
      "################Updated CSV File#################        STATE STATENAME  ST_CASE  PEDS  PERNOTMVIT  VE_TOTAL  VE_FORMS  \\\n",
      "0          1   Alabama    10001     0           0         2         2   \n",
      "1          1   Alabama    10002     0           0         2         2   \n",
      "2          1   Alabama    10003     0           0         1         1   \n",
      "3          1   Alabama    10004     0           0         1         1   \n",
      "4          1   Alabama    10005     1           1         1         1   \n",
      "...      ...       ...      ...   ...         ...       ...       ...   \n",
      "39216     56   Wyoming   560114     0           0         2         2   \n",
      "39217     56   Wyoming   560115     0           0         1         1   \n",
      "39218     56   Wyoming   560116     0           0         1         1   \n",
      "39219     56   Wyoming   560117     0           0         1         1   \n",
      "39220     56   Wyoming   560118     0           0         1         1   \n",
      "\n",
      "       PVH_INVL  PERSONS  PERMVIT  ...  DAY_WEEK DAY_WEEKNAME  YEAR HOUR  \\\n",
      "0             0        3        3  ...         7     Saturday  2022   12   \n",
      "1             0        5        5  ...         7     Saturday  2022   16   \n",
      "2             0        2        2  ...         7     Saturday  2022    1   \n",
      "3             0        1        1  ...         1       Sunday  2022   14   \n",
      "4             0        1        1  ...         1       Sunday  2022   18   \n",
      "...         ...      ...      ...  ...       ...          ...   ...  ...   \n",
      "39216         0        2        2  ...         3      Tuesday  2022   11   \n",
      "39217         0        1        1  ...         2       Monday  2022    7   \n",
      "39218         0        1        1  ...         4    Wednesday  2022   15   \n",
      "39219         0        1        1  ...         5     Thursday  2022    0   \n",
      "39220         0        4        4  ...         7     Saturday  2022    4   \n",
      "\n",
      "              HOURNAME MINUTE  MINUTENAME            TWAY_ID  TWAY_ID2 ROUTE  \n",
      "0      12:00pm-12:59pm     30          30         US-82 SR-6       NaN     2  \n",
      "1        4:00pm-4:59pm     40          40       US-231 SR-53       NaN     2  \n",
      "2        1:00am-1:59am     33          33  CR-KELLY CREEK RD       NaN     4  \n",
      "3        2:00pm-2:59pm     46          46               I-65       NaN     1  \n",
      "4        6:00pm-6:59pm     48          48               I-20       NaN     1  \n",
      "...                ...    ...         ...                ...       ...   ...  \n",
      "39216  11:00am-11:59am     27          27         I-80/US-30       NaN     1  \n",
      "39217    7:00am-7:59am      0           0             BLM RD       NaN     8  \n",
      "39218    3:00pm-3:59pm      0           0          CAREY AVE       NaN     5  \n",
      "39219    0:00am-0:59am      1           1    MOSIER GULCH RD       NaN     8  \n",
      "39220    4:00am-4:59am     57          57           CR-203-1  CR-161-1     4  \n",
      "\n",
      "[39221 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "base_path = Path(\"Resources\")\n",
    "createCSV(f\"{base_path}/accident_2022.csv.gz\",f\"{base_path}/accident_2022_label.csv\",\"us_accident_2022\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fddd26-6e9a-4868-9707-b528131134f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
